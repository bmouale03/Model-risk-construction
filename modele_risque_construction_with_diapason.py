# -*- coding: utf-8 -*-
"""Modele-Risque_Construction-with_diapason.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pp8Q5a5JANK1YBY03SddbpFcaUu0TTxn
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

"""
* ** Le dataset contient 7 facteurs explicatifs** :

  * `Niveau ingénieurs`
  * `Niveau techniciens`
  * `Expérience ingénieurs`
  * `Expérience techniciens`
  * `Technologie exploitée`
  * `Impacc Climat`
  * `Expérience entreprise`

* La variable cible (à prédire) est bien **`indice_risk_const`** (valeur continue entre \~0.3 et 0.7 d’après l’aperçu).

 Pour le **diapason du risque**, on peut fixer les seuils comme suit (basés sur la distribution de `indice_risk_const`) :

* **Critique** : si `indice_risk_const < 0.45`
* **Moyen** : si `0.45 ≤ indice_risk_const < 0.65`
* **Excellent** : si `indice_risk_const ≥ 0.65`

**Le code si-dessous :**

1. Entraîne une **régression linéaire** sur les 7 facteurs,
2. Fait des prédictions,
3. Classe automatiquement chaque entreprise dans **Critique / Moyen / Excellent**,
4. Et affiche les résultats sous forme de tableau

5. Sauvegarde un fichier Excel resultats_risque.xlsx avec les colonnes :

Facteurs explicatifs

Risque_Prédit

Diapason
"""

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# === 1. Charger les données ===
df = pd.read_excel("/content/drive/MyDrive/Indice_risk_with_7_factors.xlsx")
df
df.head()

# Séparer les variables explicatives et la cible
X = df[['Niveau ingénieurs', 'Niveau techniciens', 'Expérience ingénieurs',
        'Expérience techniciens', 'Technologie exploitée', 'Impacc Climat',
        'Expérience entreprise']]
y = df['indice_risk_const']

# === 2. Division Train/Test ===
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# === 3. Régression linéaire ===
model = LinearRegression()
model.fit(X_train, y_train)

# Prédictions sur le jeu de test
y_pred = model.predict(X_test)

# Évaluation du modèle
print("Erreur quadratique moyenne (MSE):", mean_squared_error(y_test, y_pred))

# === 4. Fonction de classification du risque ===
def classify_risk(value):
    if value < 0.45:
        return "Critique"
    elif value < 0.65:
        return "Moyen"
    else:
        return "Excellent"

# === 5. Application sur les prédictions ===
df_results = X_test.copy()
df_results["Risque_Prédit"] = y_pred
df_results["Diapason"] = df_results["Risque_Prédit"].apply(classify_risk)

# === 6. Affichage des résultats ===
print("\nExemple de résultats :")
print(df_results.head(20))

# Si tu veux sauvegarder les résultats dans un fichier Excel :
df_results.to_excel("/content/resultats_risque.xlsx", index=False)

"""**Visualisation graphique de la répartition des entreprises selon le diapason de risque :**

1.   Un histogramme qui montre combien d’entreprises tombent dans chaque catégorie (Critique / Moyen / Excellent).

2.  Un scatter plot qui compare les valeurs réelles (indice_risk_const) avec les valeurs prédites par le modèle (si les points sont proches de la ligne rouge, la régression est bonne).


"""

import matplotlib.pyplot as plt

# === 7. Visualisation de la répartition par catégorie ===
plt.figure(figsize=(6,4))
df_results["Diapason"].value_counts().plot(kind="bar")

plt.title("Répartition des entreprises par catégorie de risque")
plt.xlabel("Diapason de risque")
plt.ylabel("Nombre d'entreprises")
plt.xticks(rotation=0)
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# === 8. Visualisation des prédictions en scatter ===
plt.figure(figsize=(6,4))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([0,1],[0,1], color="red", linestyle="--")  # ligne idéale
plt.title("Prédiction vs Valeurs réelles")
plt.xlabel("Risque réel (indice_risk_const)")
plt.ylabel("Risque prédit")
plt.show()

"""**Visualisation d'un camembert (pie chart) pour visualiser la répartition par
catégorie de risque :**

Résultat :

1. Chaque secteur du camembert représente une catégorie (Critique, Moyen, Excellent)

2. Les pourcentages indiquent la proportion d’entreprises dans chaque catégorie
"""

# === 9. Visualisation en camembert ===
plt.figure(figsize=(6,6))
df_results["Diapason"].value_counts().plot(kind="pie", autopct="%1.1f%%", startangle=90, shadow=True)

plt.title("Répartition des entreprises par catégorie de risque", fontsize=14)
plt.ylabel("")  # on enlève l’étiquette par défaut
plt.show()

"""**Combinaison des 3 visualisations dans une seule figure (multi-graphique avec subplots) :**

**obtiens une figure en 1 ligne et 3 colonnes :**

1. Histogramme (barres)

2. Scatter Plot (qualité du modèle)

3. Camembert (proportions des catégories)
"""

import matplotlib.pyplot as plt

# Création de la figure avec 3 sous-graphiques
fig, axes = plt.subplots(1, 3, figsize=(18,5))

# === 1. Histogramme (barres) ===
df_results["Diapason"].value_counts().plot(kind="bar", ax=axes[0], color="skyblue")
axes[0].set_title("Répartition par catégorie (barres)")
axes[0].set_xlabel("Diapason de risque")
axes[0].set_ylabel("Nombre d'entreprises")
axes[0].grid(axis="y", linestyle="--", alpha=0.7)

# === 2. Scatter Plot (prédiction vs réel) ===
axes[1].scatter(y_test, y_pred, alpha=0.7, color="orange")
axes[1].plot([0,1],[0,1], color="red", linestyle="--")  # ligne idéale
axes[1].set_title("Prédiction vs Valeurs réelles")
axes[1].set_xlabel("Risque réel")
axes[1].set_ylabel("Risque prédit")

# === 3. Camembert (pie chart) ===
df_results["Diapason"].value_counts().plot(
    kind="pie", autopct="%1.1f%%", startangle=90, shadow=True, ax=axes[2]
)
axes[2].set_title("Répartition par catégorie (camembert)")
axes[2].set_ylabel("")

# Affichage
plt.tight_layout()
plt.show()

"""**Visualisation de la matrice de confusion (adaptée après classification Critique/Moyen/Excellent) pour évaluer si le modèle prédit bien les catégories**

**Résultat :**

1. La diagonale montre les bonnes prédictions.

2. Les cases hors diagonale montrent où le modèle se trompe (par ex. un risque "Moyen" prédit comme "Excellent").
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# === 10. Matrice de confusion ===

# On applique la fonction de classification aux vraies valeurs et aux prédictions
y_test_classes = y_test.apply(classify_risk)
y_pred_classes = pd.Series(y_pred).apply(classify_risk)

# Construire la matrice de confusion
cm = confusion_matrix(y_test_classes, y_pred_classes, labels=["Critique", "Moyen", "Excellent"])

# Affichage de la matrice
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Critique", "Moyen", "Excellent"])
disp.plot(cmap="Blues", values_format="d")
plt.title("Matrice de confusion (classification du risque)")
plt.show()

"""**Generation des indicateurs de performance (précision, rappel, F1-score) pour chaque catégorie de risque**

**Résultat :**

1. Précision (precision) → parmi ce que le modèle a prédit, combien sont corrects ?

2. Rappel (recall) → parmi les vrais cas d’une catégorie, combien le modèle a bien détectés ?

3. F1-score → moyenne harmonique précision + rappel (équilibre global).

4. Support → combien d’exemples réels dans chaque catégorie.
"""

from sklearn.metrics import classification_report

# === 11. Rapport de classification ===
print("=== Rapport de performance par catégorie ===")
print(classification_report(y_test_classes, y_pred_classes, target_names=["Critique", "Moyen", "Excellent"]))

"""**Visualisation de heatmap colorée (matrice de confusion améliorée) avec seaborn pour que ce soit plus visuel**

**Résultat :**

1. Les cases sont colorées selon leur intensité (plus foncé = plus de cas).

2. On voit immédiatement où le modèle réussit ou échoue.

"""

import seaborn as sns

# === 12. Heatmap de la matrice de confusion ===
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["Critique", "Moyen", "Excellent"],
            yticklabels=["Critique", "Moyen", "Excellent"])

plt.title("Matrice de confusion (Heatmap)")
plt.xlabel("Prédit")
plt.ylabel("Réel")
plt.show()

"""**Rapport automatisé qui contient :**

1. La matrice de confusion (heatmap).

2. Le rapport de classification (précision, rappel, F1).

3. Et on enregistre tout dans un fichier Excel.

Résultat : On obtient un fichier rapport_risque.xlsx dans le Colab, avec :

*   Onglet 1 : Précision, Rappel, F1-score pour Critique, Moyen, Excellent.
*   Onglet 2 : La matrice de confusion détaillée.
"""

import pandas as pd
from sklearn.metrics import classification_report

# === 13. Générer le rapport de classification sous forme de DataFrame ===
report_dict = classification_report(y_test_classes, y_pred_classes,
                                    target_names=["Critique", "Moyen", "Excellent"],
                                    output_dict=True)

df_report = pd.DataFrame(report_dict).transpose()

# === 14. Matrice de confusion sous forme de DataFrame ===
df_cm = pd.DataFrame(cm,
                     index=["Réel_Critique", "Réel_Moyen", "Réel_Excellent"],
                     columns=["Prédit_Critique", "Prédit_Moyen", "Prédit_Excellent"])

# === 15. Sauvegarde dans un fichier Excel avec 2 onglets ===
with pd.ExcelWriter("/content/rapport_risque.xlsx") as writer:
    df_report.to_excel(writer, sheet_name="Classification_Report")
    df_cm.to_excel(writer, sheet_name="Confusion_Matrix")

print("Rapport sauvegardé sous : rapport_risque.xlsx")

